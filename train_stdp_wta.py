'''
This file trains a STDP network with strict WTA inhibition at 4 different numbers of neurons (50, 100, 200, 400). 
The network is evaluated at every 10 epochs for reconstruction accuracy (MSE, SSIM, and Sparsity). 
At every 10 epochs, an image of the reconstructions are saved as well as the receptive fields (weights) of the model.

It will also commence a queue of training for NMF, PCA, and a surrogate backpropagation network at
the same number of neurons/basis functions. The surrogate backpropagation network is trained at a fixed number of epochs,
not a 100. These three dimensionality reduction/training paradigms will also be evaluated ONCE after they 
have run to completion, upon which they'll produce their reconstruction accuracy (MSE, SSIM, and Sparsity). 
An image of the reconstructions are saved as well as the receptive fields (weights) of the model. 
'''
import torch 
import pandas as pd
from torchvision import datasets, transforms

from hyperparameters.hyperparameters_stdp import *
from model.model_stdp_WTA import *

from train.train_model_stdp import *
from train.train_decoder import *
from train.evaluate_decoder import *

from learning.stdp import *

# Datasets
 
transform = transforms.Compose([transforms.ToTensor(),
                                dog_transform])

train_dataset = datasets.FashionMNIST('assets/FashionMNIST', train=True, transform=transform, download=True)
test_dataset = datasets.FashionMNIST('assets/FashionMNIST', train=False, transform=transform, download=True)

train_set = torch.utils.data.Subset(train_dataset, range(num_samples))
test_set = torch.utils.data.Subset(test_dataset, range(num_samples))

train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True) 
test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=True)

# Saving

################# STDP Network + Strict WTA Inhibition (50, 100, 200, 400) #################

metrics_dict = {
    "50": [[],[]],
    "100": [[],[]],
    "200": [[],[]],
    "400": [[],[]],
}

for net_size in num_output:

    save_path = f"data/{net_size}_neuron_stdp"
    
    model = Net(num_input=num_input,
                num_output=net_size,
                beta=beta,
                threshold=threshold,
                reset_mechanism=reset_mechanism)
    
    for epoch in range(num_epochs):

        train_model(model=model,
                    update_params=update_params,
                    train_loader=train_loader,
                    num_steps=num_steps,
                    epoch=epoch,
                    save_path=save_path)
        
        viz_model(model=model,
                  epoch=epoch,
                  save_path=save_path)
        
        if (epoch == 0) or (epoch % 10 == 0) or (epoch == num_epochs - 1): 

            # we should take the model and its weights generated by train_model
            # instantiate a new model based on model_stdp, not model_stdp_WTA.py 
            # and then use that to train the decoder 

            decoder = train_decoder(wta_model=model,
                          net_size=net_size,
                          train_loader=train_loader,
                          num_steps=num_steps,
                          epoch=epoch,
                          save_path=save_path)
            
            avg_ssim, avg_mse = evaluate_decoder(wta_model=model,
                                                  net_size = net_size,
                                                  test_loader=test_loader,
                                                  decoder=decoder,
                                                  num_steps=num_steps,
                                                  epoch=epoch,
                                                  save_path=save_path)

            key = str(net_size)
            metrics_dict[key][0].append(avg_ssim)
            metrics_dict[key][1].append(avg_mse)

rows = []
for net_size, (ssim_list, mse_list) in metrics_dict.items():
    for epoch_idx, (ssim, mse) in enumerate(zip(ssim_list, mse_list)):
        rows.append({
            "net_size": int(net_size),
            "epoch_idx": epoch_idx,   # idx within your saved epochs
            "avg_ssim": ssim,
            "avg_mse": mse
        })

df = pd.DataFrame(rows)
df.to_csv("data/metrics.csv", index=False)
